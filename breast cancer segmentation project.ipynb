{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "import re\n",
    "\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm #progress bar\n",
    "from skimage.io import imread, imshow\n",
    "from skimage.transform import resize\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "PATH_BENIGN = 'C:/Users/Marta/Desktop/MI Medical Image Segmentation Project/Breast Cancer Segmentation Project/data/data/benign/'\n",
    "PATH_MALIGNANT = 'C:/Users/Marta/Desktop/MI Medical Image Segmentation Project/Breast Cancer Segmentation Project/data/data/malignant/'\n",
    "PATH_NORMAL = 'C:/Users/Marta/Desktop/MI Medical Image Segmentation Project/Breast Cancer Segmentation Project/data/data/normal/'\n",
    "\n",
    "def check_if_folder_exists(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "\n",
    "def przenies_pliki(folder_zrodlowy):\n",
    "    check_if_folder_exists(folder_zrodlowy+'images')\n",
    "    check_if_folder_exists(folder_zrodlowy+'masks')\n",
    "\n",
    "    for plik in os.listdir(folder_zrodlowy): #listuje pliki w katalogu zrodlowym\n",
    "        if (not os.path.isdir(folder_zrodlowy + plik)):\n",
    "            if re.match(r'.*mask.*', plik): #regex, dopasowane wszystkie stringi ktore w srodku maja napis mask, a na lewo i prawo od napisu mask maja od 0 do nieskonczonosci dowolnych znakow\n",
    "                shutil.move(folder_zrodlowy + plik, folder_zrodlowy + 'masks/' + plik) #przenosimy plik do folderu z maskami\n",
    "                #print(plik)\n",
    "            else:\n",
    "                shutil.move(folder_zrodlowy + plik, folder_zrodlowy + 'images/' + plik)\n",
    "                \n",
    "\n",
    "przenies_pliki(PATH_BENIGN) #wyswitlenie nazw plikow ktore maja mask w nazwie\n",
    "przenies_pliki(PATH_MALIGNANT)\n",
    "przenies_pliki(PATH_NORMAL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TRAINING = 'C:/Users/Marta/Desktop/MI Medical Image Segmentation Project/Breast Cancer Segmentation Project/data/data/training/'\n",
    "PATH_TESTING = 'C:/Users/Marta/Desktop/MI Medical Image Segmentation Project/Breast Cancer Segmentation Project/data/data/testing/'\n",
    "\n",
    "def create_directory_structure(test_dir, train_dir):\n",
    "    check_if_folder_exists(test_dir + 'benign/' + 'images')\n",
    "    check_if_folder_exists(test_dir + 'malignant/' + 'images')\n",
    "    check_if_folder_exists(test_dir + 'normal/' + 'images')\n",
    "\n",
    "    check_if_folder_exists(test_dir + 'benign/' + 'masks')\n",
    "    check_if_folder_exists(test_dir + 'malignant/' + 'masks')\n",
    "    check_if_folder_exists(test_dir + 'normal/' + 'masks')\n",
    "\n",
    "    check_if_folder_exists(train_dir + 'benign/' + 'images')\n",
    "    check_if_folder_exists(train_dir + 'malignant/' + 'images')\n",
    "    check_if_folder_exists(train_dir + 'normal/' + 'images')\n",
    "\n",
    "    check_if_folder_exists(train_dir + 'benign/' + 'masks')\n",
    "    check_if_folder_exists(train_dir + 'malignant/' + 'masks')\n",
    "    check_if_folder_exists(train_dir + 'normal/' + 'masks')\n",
    "\n",
    "\n",
    "create_directory_structure(PATH_TESTING, PATH_TRAINING)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(test_dir, train_dir, source_dir, split_ratio = 0.2):\n",
    "    images_names = os.listdir(source_dir + 'images') #lista z nazwami imagesów\n",
    "    images_count = len(images_names) \n",
    "    test_count = int(split_ratio * images_count)\n",
    "    for i in range(0, test_count):\n",
    "        random_number = random.randint(0, images_count - i) #z kazda iteracja zmniejsza sie liczba dostepnych obrazow\n",
    "        images_count -= 1\n",
    "        moved_image = images_names.pop(random_number)\n",
    "        #print(moved_image) #nazwy tych co przeniesiemy do zbioru testujacego\n",
    "        masks_to_move = [] #pusta lista\n",
    "        masks_names = os.listdir(source_dir + 'masks') #mam nazwy masek: z benignow biore do listy nazwy zdjec z maskami\n",
    "        pattern = moved_image.split(\".\")[0] #to co przed \".png\"\n",
    "        pattern = re.escape(pattern)        \n",
    "\n",
    "        for mask in masks_names:\n",
    "            if re.match(fr'{pattern}.*', mask): #regex, dopasowane wszystkie stringi ktore w srodku maja napis mask, a na lewo i prawo od napisu mask maja od 0 do nieskonczonosci dowolnych znakow\n",
    "                shutil.move(source_dir + 'masks/' + mask, test_dir + 'masks/' + mask) #przenosimy plik do folderu z maskami\n",
    "                #print(mask + \"and\" + pattern )\n",
    "\n",
    "        shutil.move(source_dir + 'images/' + moved_image, test_dir + 'images/' + moved_image)\n",
    "\n",
    "    images_names = os.listdir(source_dir + 'images')\n",
    "    for image in images_names:\n",
    "        shutil.move(source_dir + 'images/' + image, train_dir + 'images/' + image)\n",
    "\n",
    "\n",
    "    masks_names = os.listdir(source_dir + 'masks')\n",
    "    for mask in masks_names:\n",
    "        shutil.move(source_dir + 'masks/' + mask, train_dir + 'masks/' + mask)\n",
    "            \n",
    "            \n",
    "\n",
    "\n",
    "split_data(PATH_TESTING + 'benign/', PATH_TRAINING + 'benign/', PATH_BENIGN) #30% benigna\n",
    "split_data(PATH_TESTING + 'malignant/', PATH_TRAINING + 'malignant/', PATH_MALIGNANT)\n",
    "split_data(PATH_TESTING + 'normal/', PATH_TRAINING + 'normal/', PATH_NORMAL)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 37\n",
    "np.random.seed = seed\n",
    "\n",
    "img_width = 128\n",
    "img_height = 128\n",
    "img_channels = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(625, 128, 128, 3)\n",
      "Resizing training images and masks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/107 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:08<00:00, 12.90it/s]\n",
      "100%|██████████| 350/350 [00:15<00:00, 23.01it/s]\n",
      "100%|██████████| 168/168 [00:06<00:00, 25.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(155, 128, 128, 3)\n",
      "Resizing training images and masks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:02<00:00, 10.01it/s]\n",
      "100%|██████████| 87/87 [00:06<00:00, 13.01it/s]\n",
      "100%|██████████| 42/42 [00:02<00:00, 15.20it/s]\n"
     ]
    }
   ],
   "source": [
    "def resize_images(path_to_data):\n",
    "    subfolder_names = [\"normal\", \"benign\", \"malignant\"]\n",
    "    \n",
    "    normal_imgs_file_names = os.listdir(path_to_data + \"normal/images\")\n",
    "    benign_imgs_file_names = os.listdir(path_to_data + \"benign/images\")\n",
    "    malignant_imgs_file_names = os.listdir(path_to_data + \"malignant/images\")\n",
    "\n",
    "    normal_masks_file_names = os.listdir(path_to_data + \"normal/masks\")\n",
    "    benign_masks_file_names = os.listdir(path_to_data + \"benign/masks\")\n",
    "    malignant_masks_file_names = os.listdir(path_to_data + \"malignant/masks\")\n",
    "\n",
    "    all_img_file_names = [normal_imgs_file_names, benign_imgs_file_names, malignant_imgs_file_names]\n",
    "    all_mask_file_names = [normal_masks_file_names, benign_masks_file_names, malignant_masks_file_names]\n",
    "\n",
    "    number_of_training_imgs = len(normal_imgs_file_names) + len(benign_imgs_file_names) + len(malignant_imgs_file_names)\n",
    "\n",
    "    #i fill matrix with zeros firstly\n",
    "    #independent, images from trainng set\n",
    "    X_matrix = np.zeros((number_of_training_imgs, img_height, img_width, img_channels), dtype=np.uint8)\n",
    "\n",
    "    #dependent, what i try to predict. 1 is bool (yes or no). Masks from training set\n",
    "    #idk but i guess that 3 will be for 3 classes normal, benign and malignant\n",
    "    Y_matrix = np.zeros((number_of_training_imgs, img_height, img_width, 3), dtype=bool)\n",
    "    print(Y_matrix.shape)\n",
    "    print('Resizing training images and masks')\n",
    "\n",
    "    counter = 0\n",
    "    for class_id, subfolder in enumerate(subfolder_names):\n",
    "        #print(class_id, subfolder)\n",
    "        current_imgs_file_names = all_img_file_names[class_id] #wszystkie nazwy zdjec np z benign\n",
    "        current_masks_file_names = all_mask_file_names[class_id]\n",
    "        # if(class_id == 0):\n",
    "        #     continue\n",
    "        for img_file_name in tqdm(current_imgs_file_names): \n",
    "            # if not(img_file_name == \"benign (4).png\"):\n",
    "            #     continue\n",
    "            path = path_to_data + f\"{subfolder}/images/\" + img_file_name #iterujemy po plikach np w benign\n",
    "            img = imread(path)[:,:,:img_channels] \n",
    "            img = resize(img, (img_height, img_width), mode='constant', preserve_range=True)\n",
    "            X_matrix[counter] = img #all images\n",
    "            \n",
    "            \n",
    "            mask = np.zeros((img_height, img_width, 3), dtype=bool) #tensor o takich wymiarach, wszystkie komorki ustwiam na zero\n",
    "            pattern = img_file_name.split(\".\")[0] #np benign (1)\n",
    "            pattern = re.escape(pattern) #nie traktowal nawiasow jako special character\n",
    "            corresponding_masks = [curr_mask for curr_mask in current_masks_file_names if re.match(fr'{pattern}.*', curr_mask)] #dodaj curr_mask do listy jesli spelnia warunki    \n",
    "            # print(img_file_name)\n",
    "            for mask_file in corresponding_masks:\n",
    "                mask_ = imread(path_to_data + f'{subfolder}/masks/' + mask_file, as_gray=True) #wczytanie zdjecia w skali szarosci\n",
    "\n",
    "                mask_ = np.expand_dims(resize(mask_, (img_height, img_width), mode='constant',  #resize do 128x128 i dodanie 3 kanału\n",
    "                                             preserve_range=True), axis=-1)\n",
    "                \n",
    "                mask_ = np.repeat(mask_, repeats=3, axis=-1)    #zrobienie 128x128x3\n",
    "                mask_ = mask_.astype(\"bool\")                    #\n",
    "                #powyzej kazdy z 3 kanalow jest taki sam jak maska\n",
    "                # #mask_[:,:,1] = 0.5\n",
    "                # print(mask_file, np.unique(mask_[:,:,1], return_counts=True))\n",
    "                mask = np.maximum(mask, mask_)  #merging masks to get 1 mask. At every pixel i look for max value, take this value and create a mask\n",
    "            # print(\"\\n\\n\\n\",np.unique(mask[:,:,1], return_counts=True))\n",
    "            mask_ = mask_.astype(\"float\")\n",
    "            if(class_id == 0):\n",
    "                mask[:,:,0] = 1 - mask[:,:,0]\n",
    "            elif(class_id == 1):\n",
    "                mask[:,:,2] = 0\n",
    "                mask[:,:,0] = 1 - mask[:,:,0]\n",
    "            else:\n",
    "                mask[:,:,1] = 0\n",
    "                mask[:,:,0] = 1 - mask[:,:,0]\n",
    "            # print(\"normal\",mask_file,np.unique(mask[:,:,0], return_counts=True))\n",
    "            # print(\"brajan\",mask_file,np.unique(mask[:,:,1], return_counts=True))\n",
    "            # print(\"marian\",mask_file,np.unique(mask[:,:,2], return_counts=True))\n",
    "            # break\n",
    "            Y_matrix[counter] = mask\n",
    "            counter+=1\n",
    "    return X_matrix, Y_matrix\n",
    "# train_ids = next(os.walk(train_path))[1] #name of folder with train data\n",
    "# test_ids = next(os.walk(test_path))[1]\n",
    "#start from [1] bc otherwise it would be name stage1_train\n",
    "\n",
    "\n",
    "\n",
    "X_train, Y_train = resize_images(PATH_TRAINING)\n",
    "X_test, Y_test = resize_images(PATH_TESTING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((625, 128, 128, 3),\n",
       " (625, 128, 128, 3),\n",
       " (155, 128, 128, 3),\n",
       " (155, 128, 128, 3))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, Y_train.shape, X_test.shape, Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Resizing training images and masks')\n",
    "for n, id_ in tqdm(enumerate(train_ids), total=len(train_ids)):   \n",
    "    path = train_path + id_ #id_ is path to image\n",
    "    img = imread(path + '/images/' + id_ + '.png')[:,:,:img_channels]  \n",
    "    img = resize(img, (img_height, img_width), mode='constant', preserve_range=True)\n",
    "    X_train[n] = img  #Fill empty X_train with values from img\n",
    "    mask = np.zeros((img_height, img_width, 1), dtype=bool)\n",
    "    for mask_file in next(os.walk(path + '/masks/'))[2]:\n",
    "        mask_ = imread(path + '/masks/' + mask_file)\n",
    "        mask_ = np.expand_dims(resize(mask_, (img_height, img_width), mode='constant',  \n",
    "                                      preserve_range=True), axis=-1)\n",
    "        mask = np.maximum(mask, mask_)  #merging masks to get 1 mask. At every pixel i look for max value, take this value and create a mask\n",
    "            \n",
    "    Y_train[n] = mask   \n",
    "\n",
    "# test images\n",
    "X_test = np.zeros((len(test_ids), img_height, img_width, img_channels), dtype=np.uint8)\n",
    "sizes_test = []\n",
    "print('Resizing test images') \n",
    "for n, id_ in tqdm(enumerate(test_ids), total=len(test_ids)):\n",
    "    path = test_path + id_\n",
    "    img = imread(path + '/images/' + id_ + '.png')[:,:,:img_channels]\n",
    "    sizes_test.append([img.shape[0], img.shape[1]])\n",
    "    img = resize(img, (img_height, img_width), mode='constant', preserve_range=True)\n",
    "    X_test[n] = img\n",
    "\n",
    "print('Done!')\n",
    "\n",
    "#randomly pick image and show it with associated mask\n",
    "image_x = random.randint(0, len(train_ids))\n",
    "imshow(X_train[image_x])\n",
    "plt.show()\n",
    "imshow(np.squeeze(Y_train[image_x]))\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#building U-net model\n",
    "\n",
    "#encoder path\n",
    "#first layer\n",
    "inputs = tf.keras.layers.Input((img_width, img_height, img_channels)) #0-255\n",
    "\n",
    "#convert pixel into floating point number bc keras layers deal with floating numbers\n",
    "s = tf.keras.layers.Lambda(lambda x: x / 255)(inputs)\n",
    "\n",
    "#convolutional layers\n",
    "#padding=same to have the same output image size as input\n",
    "c1 = tf.keras.layers.Conv2D(16, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(s) \n",
    "#kernel_initializer to start with some weights,\n",
    "#he_normal does it by truncated normal distribution (centered around zero)\n",
    "\n",
    "\n",
    "#drop 10% pixels\n",
    "c1 = tf.keras.layers.Dropout(0.1)(c1)\n",
    "\n",
    "#second convolutional layer\n",
    "c1 = tf.keras.layers.Conv2D(16, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(c1) #kernel_initializer to start with some weights, he_normal does it by truncated normal distribution (centered around zero)\n",
    "\n",
    "\n",
    "#max pooling\n",
    "p1 = tf.keras.layers.MaxPooling2D((2,2))(c1)\n",
    "\n",
    "###\n",
    "c2 = tf.keras.layers.Conv2D(32, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(p1)\n",
    "c2 = tf.keras.layers.Dropout(0.1)(c2)\n",
    "c2 = tf.keras.layers.Conv2D(32, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(c2)\n",
    "p2 = tf.keras.layers.MaxPooling2D((2,2))(c2)\n",
    "\n",
    "c3 = tf.keras.layers.Conv2D(32, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(p2)\n",
    "c3 = tf.keras.layers.Dropout(0.1)(c3)\n",
    "c3 = tf.keras.layers.Conv2D(32, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(c3)\n",
    "p3 = tf.keras.layers.MaxPooling2D((2,2))(c3)\n",
    "\n",
    "c4 = tf.keras.layers.Conv2D(32, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(p3)\n",
    "c4 = tf.keras.layers.Dropout(0.1)(c4)\n",
    "c4 = tf.keras.layers.Conv2D(32, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(c4)\n",
    "p4 = tf.keras.layers.MaxPooling2D((2,2))(c4)\n",
    "\n",
    "c5 = tf.keras.layers.Conv2D(32, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(p4)\n",
    "c5 = tf.keras.layers.Dropout(0.1)(c5)\n",
    "c5 = tf.keras.layers.Conv2D(32, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(c5)\n",
    "p5 = tf.keras.layers.MaxPooling2D((2,2))(c5)\n",
    "\n",
    "#decoder path\n",
    "\n",
    "#Conv2DTranspose is opposite to Conv2D\n",
    "u6 = tf.keras.layers.Conv2DTranspose(128, (2,2), strides=(2,2), padding='same')(c5)\n",
    "u6 = tf.keras.layers.concatenate([u6, c4])\n",
    "c6 = tf.keras.layers.Conv2D(128, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(u6)\n",
    "c6 = tf.keras.layers.Dropout(0.2)(c6)\n",
    "c6 = tf.keras.layers.Conv2D(128, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(c6)\n",
    "\n",
    "u7 = tf.keras.layers.Conv2DTranspose(64, (2,2), strides=(2,2), padding='same')(c6)\n",
    "u7 = tf.keras.layers.concatenate([u7, c3])\n",
    "c7 = tf.keras.layers.Conv2D(64, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(u7)\n",
    "c7 = tf.keras.layers.Dropout(0.2)(c7)\n",
    "c7 = tf.keras.layers.Conv2D(64, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(c7)\n",
    "\n",
    "u8 = tf.keras.layers.Conv2DTranspose(32, (2,2), strides=(2,2), padding='same')(c7)\n",
    "u8 = tf.keras.layers.concatenate([u8, c2])\n",
    "c8 = tf.keras.layers.Conv2D(32, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(u8)\n",
    "c8 = tf.keras.layers.Dropout(0.2)(c8)\n",
    "c8 = tf.keras.layers.Conv2D(32, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(c8)\n",
    "\n",
    "u9 = tf.keras.layers.Conv2DTranspose(16, (2,2), strides=(2,2), padding='same')(c8)\n",
    "u9 = tf.keras.layers.concatenate([u9, c1])\n",
    "c9 = tf.keras.layers.Conv2D(16, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(u9)\n",
    "c9 = tf.keras.layers.Dropout(0.2)(c9)\n",
    "c9 = tf.keras.layers.Conv2D(32, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(c9)\n",
    "\n",
    "outputs = tf.keras.layers.Conv2D(1, (1,1), activation='sigmoid')(c9)\n",
    "\n",
    "#optimizer tries to minimize loss function, accuracy to measure model's performance after training\n",
    "#adam works like backpropagation to train model, can also be stochastic gradient descent\n",
    "#loss=binary_crossentropy bc pixel belongs to mask or not\n",
    "model = tf.keras.Model(inputs=[inputs], outputs=[outputs])\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "#callbacks\n",
    "checkpointer = tf.keras.callbacks.ModelCheckpoint('model_for_nuclei.keras', verbose=1, save_best_only=True)\n",
    "#monituruje postep modelu i zapisuje do pliku. verbose = 1 oznacza, ze podczas zapisywania modelu bedzie wyswietlany komunikat\n",
    "#save_best_only aby zapisac najlepszą wersję modelu\n",
    "\n",
    "\n",
    "#trening zatrzymany po 2 kolejnych epokach, w których wartość val_loss (strat walidacyjnych) nie ulegnie poprawie. \n",
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(patience=2, monitor='val_loss'),\n",
    "    tf.keras.callbacks.TensorBoard(log_dir='logs') #to create logs\n",
    "]\n",
    "\n",
    "#training model\n",
    "results = model.fit(X_train, Y_train, validation_split=0.1, batch_size=16, epochs=25, callbacks=callbacks)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####\n",
    "\n",
    "idx = random.randint(0, len(X_train))\n",
    "\n",
    "# - predykcja na zbiorze treningowym `X_train` za pomocą wytrenowanego modelu.\n",
    "# - Przy użyciu metody `predict` model oblicza prognozy na podstawie danych treningowych.\n",
    "# - Tutaj wykorzystywane jest pierwsze 90% danych treningowych. X_train.shape[0] to liczba przykladow. Biorę od pierwszego przykladu \"\":\"\" do 90% wszystkich\n",
    "#Dla verbose=1: W trakcie predykcji wyświetlane będą informacje postępu, takie jak numer aktualnie przetwarzanego przykładu. Dzięki temu można śledzić postęp operacji i zobaczyć, ile czasu pozostało do ukończenia procesu predykcji.\n",
    "#Dla verbose=2: Oprócz informacji wyświetlanych dla verbose=1, wyświetlane będą dodatkowe szczegóły, takie jak czas trwania poszczególnych kroków i inne informacje diagnostyczne.\n",
    "preds_train = model.predict(X_train[:int(X_train.shape[0]*0.9)], verbose=1)\n",
    "\n",
    "#ostatnie 10% danych bedzie walidacyjne\n",
    "preds_val = model.predict(X_train[int(X_train.shape[0]*0.9):], verbose=1)\n",
    "\n",
    "#testing model on data that were not used during model training\n",
    "preds_test = model.predict(X_test, verbose=1)\n",
    "\n",
    "#Predykcje przekraczające wartość 0.5 są traktowane jako piksele o wartości 1, a pozostałe \n",
    "#jako piksele o wartości 0 (przy użyciu astype(np.uint8)).\n",
    "preds_train_t = (preds_train > 0.5).astype(np.uint8)\n",
    "preds_val_t = (preds_val > 0.5).astype(np.uint8)\n",
    "preds_test_t = (preds_test > 0.5).astype(np.uint8)\n",
    "\n",
    "\n",
    "# check on some random training samples\n",
    "ix = random.randint(0, len(preds_train_t))\n",
    "imshow(X_train[ix]) #obraz treningowy dla losowego indeksu ix\n",
    "plt.show()\n",
    "imshow(np.squeeze(Y_train[ix])) #rzeczywista maska dla obrazu treningowego o indeksie ix\n",
    "plt.show()\n",
    "imshow(np.squeeze(preds_train_t[ix])) #predykcja modelu dla obrazu treningowego o indeksie ix\n",
    "plt.show()\n",
    "\n",
    "#check on some random validation samples\n",
    "ix = random.randint(0, len(preds_val_t))\n",
    "imshow(X_train[int(X_train.shape[0]*0.9):][ix])\n",
    "plt.show()\n",
    "imshow(np.squeeze(Y_train[int(Y_train.shape[0]*0.9):][ix]))\n",
    "plt.show()\n",
    "imshow(np.squeeze(preds_val_t[ix]))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
